{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Find a small float to avoid division by zero\n",
    "epsilon = np.finfo(float).eps\n",
    "# Sigmoid function and its differentiation\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z.clip(-500, 500)))\n",
    "def dsigmoid(z):\n",
    "    s = sigmoid(z)\n",
    "    return 2 * s * (1-s)\n",
    "# ReLU function and its differentiation\n",
    "def relu(z):\n",
    "    return np.maximum(0, z)\n",
    "def drelu(z):\n",
    "    return (z > 0).astype(float)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Loss function L(y, yhat) and its differentiation\n",
    "def cross_entropy(y, yhat):\n",
    "\n",
    "    ''' Binary cross entropy function\n",
    "    L = - y log yhat - (1-y) log (1-yhat)\n",
    "    Args:\n",
    "    y, yhat (np.array): 1xn matrices which n are the number of data instances\n",
    "    Returns:\n",
    "    average cross entropy value of shape 1x1, averaging over the n instances\n",
    "    '''\n",
    "    return (-(y.T @ np.log(yhat.clip(epsilon)) +\n",
    "          (1-y.T) @ np.log((1-yhat).clip(epsilon))\n",
    "          ) / y.shape[1])\n",
    "\n",
    "\n",
    "def d_cross_entropy(y, yhat):\n",
    "    '''dL/dyhat '''\n",
    "    return (- np.divide(y, yhat.clip(epsilon))\n",
    "        + np.divide(1-y, (1-yhat).clip(epsilon)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp:\n",
    "    def __init__(self, layersizes, activations, derivatives, lossderiv):\n",
    "        self.layersizes = layersizes\n",
    "        self.activations = activations\n",
    "        self.derivatives = derivatives\n",
    "        self.lossderiv = lossderiv\n",
    "        L = len(self.layersizes)\n",
    "        self.z = [None]*L\n",
    "        self.w = [None]*L\n",
    "        self.b = [None]*L\n",
    "        self.a = [None]*L\n",
    "        self.dz = [None]*L\n",
    "        self.dw = [None]*L\n",
    "        self.db = [None]*L\n",
    "        self.da = [None]*L\n",
    "\n",
    "    def initialize(self, seed=42):\n",
    "        np.random.seed(seed)\n",
    "        sigma = 0.1\n",
    "        for l, (n_in, n_out) in enumerate(zip(self.layersizes, self.layersizes[1:]), 1):\n",
    "            self.w[l] = np.random.randn(n_in, n_out) * sigma\n",
    "            self.b[l] = np.random.randn(1, n_out) * sigma\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        self.a[0] = x\n",
    "        for l, func in enumerate(self.activations, 1):\n",
    "\n",
    "            self.z[l] = (self.a[l-1] @ self.w[l]) + self.b[l]\n",
    "\n",
    "            self.a[l] = func(self.z[l])\n",
    "        return self.a[-1]\n",
    "\n",
    "    def backward(self, y, yhat):\n",
    "        self.da[-1] = self.lossderiv(y, yhat)\n",
    "        for l, func in reversed(list(enumerate(self.derivatives, 1))):\n",
    "\n",
    "            self.dz[l] = self.da[l]*func(self.z[l])\n",
    "            self.dw[l] = self.a[l-1].T@self.dz[l]\n",
    "            self.db[l] = np.mean(self.dz[l], axis=0, keepdims=True)\n",
    "            self.da[l-1] = self.dz[l] @ self.w[l].T\n",
    "\n",
    "    def update(self, eta):\n",
    "        for l in range(1, len(self.w)):\n",
    "            self.w[l] -= eta*self.dw[l]\n",
    "            self.b[l] -= eta * self.db[l]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Make data: Two circles on x-y plane as a classification problem\n",
    "X, y = make_circles(n_samples=1000, factor=0.5, noise=0.1)\n",
    "y = y.reshape(-1,1) # our model expects a 2D array of (n_sample, n_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training - loss value [[693.63164393]] accuracy 0.5\n"
     ]
    }
   ],
   "source": [
    "model = mlp(layersizes=[2, 4, 3, 1],\n",
    "activations=[relu, relu, sigmoid],\n",
    "derivatives=[drelu, drelu, dsigmoid],\n",
    "lossderiv=d_cross_entropy)\n",
    "model.initialize()\n",
    "yhat = model.forward(X)\n",
    "loss = cross_entropy(y, yhat)\n",
    "score = accuracy_score(y, (yhat > 0.5))\n",
    "print(f\"Before training - loss value {loss} accuracy {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 - loss value [[693.49898455]] accuracy 0.5\n",
      "Iteration 1 - loss value [[693.49715475]] accuracy 0.5\n",
      "Iteration 2 - loss value [[693.49532309]] accuracy 0.5\n",
      "Iteration 3 - loss value [[693.49348719]] accuracy 0.5\n",
      "Iteration 4 - loss value [[693.49164582]] accuracy 0.5\n",
      "Iteration 5 - loss value [[693.48979572]] accuracy 0.5\n",
      "Iteration 6 - loss value [[693.48793506]] accuracy 0.5\n",
      "Iteration 7 - loss value [[693.4860605]] accuracy 0.5\n",
      "Iteration 8 - loss value [[693.48416805]] accuracy 0.5\n",
      "Iteration 9 - loss value [[693.48225403]] accuracy 0.5\n",
      "Iteration 10 - loss value [[693.48031224]] accuracy 0.5\n",
      "Iteration 11 - loss value [[693.47833433]] accuracy 0.5\n",
      "Iteration 12 - loss value [[693.47631829]] accuracy 0.5\n",
      "Iteration 13 - loss value [[693.47425103]] accuracy 0.5\n",
      "Iteration 14 - loss value [[693.472122]] accuracy 0.5\n",
      "Iteration 15 - loss value [[693.46991919]] accuracy 0.5\n",
      "Iteration 16 - loss value [[693.46763382]] accuracy 0.5\n",
      "Iteration 17 - loss value [[693.4652324]] accuracy 0.5\n",
      "Iteration 18 - loss value [[693.46270518]] accuracy 0.5\n",
      "Iteration 19 - loss value [[693.4600305]] accuracy 0.5\n",
      "Iteration 20 - loss value [[693.45716948]] accuracy 0.5\n",
      "Iteration 21 - loss value [[693.454093]] accuracy 0.5\n",
      "Iteration 22 - loss value [[693.4507505]] accuracy 0.5\n",
      "Iteration 23 - loss value [[693.44710833]] accuracy 0.5\n",
      "Iteration 24 - loss value [[693.44311526]] accuracy 0.5\n",
      "Iteration 25 - loss value [[693.4387144]] accuracy 0.5\n",
      "Iteration 26 - loss value [[693.43374097]] accuracy 0.5\n",
      "Iteration 27 - loss value [[693.42803944]] accuracy 0.5\n",
      "Iteration 28 - loss value [[693.42139967]] accuracy 0.5\n",
      "Iteration 29 - loss value [[693.41324657]] accuracy 0.5\n",
      "Iteration 30 - loss value [[693.40288271]] accuracy 0.5\n",
      "Iteration 31 - loss value [[693.38914956]] accuracy 0.5\n",
      "Iteration 32 - loss value [[693.37218877]] accuracy 0.5\n",
      "Iteration 33 - loss value [[693.35492512]] accuracy 0.5\n",
      "Iteration 34 - loss value [[693.33651959]] accuracy 0.5\n",
      "Iteration 35 - loss value [[693.31674384]] accuracy 0.5\n",
      "Iteration 36 - loss value [[693.29553463]] accuracy 0.5\n",
      "Iteration 37 - loss value [[693.27265425]] accuracy 0.5\n",
      "Iteration 38 - loss value [[693.24738333]] accuracy 0.5\n",
      "Iteration 39 - loss value [[693.21937505]] accuracy 0.5\n",
      "Iteration 40 - loss value [[693.18830541]] accuracy 0.5\n",
      "Iteration 41 - loss value [[693.15436451]] accuracy 0.5\n",
      "Iteration 42 - loss value [[693.11766129]] accuracy 0.5\n",
      "Iteration 43 - loss value [[693.07764876]] accuracy 0.5\n",
      "Iteration 44 - loss value [[693.03467582]] accuracy 0.5\n",
      "Iteration 45 - loss value [[692.98903085]] accuracy 0.5\n",
      "Iteration 46 - loss value [[692.9402556]] accuracy 0.5\n",
      "Iteration 47 - loss value [[692.88848056]] accuracy 0.5\n",
      "Iteration 48 - loss value [[692.83229732]] accuracy 0.5\n",
      "Iteration 49 - loss value [[692.77282266]] accuracy 0.5\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 50\n",
    "learning_rate = 0.005\n",
    "for n in range(n_epochs):\n",
    "    model.forward(X)\n",
    "    yhat = model.a[-1]\n",
    "    model.backward(y, yhat)\n",
    "    model.update(learning_rate)\n",
    "    loss = cross_entropy(y, yhat)\n",
    "    score = accuracy_score(y, (yhat > 0.5))\n",
    "    print(f\"Iteration {n} - loss value {loss} accuracy {score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34318cfe4829af221e5477cadc97d20e2fe9ea9ad002c04600364c092214ecf0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
